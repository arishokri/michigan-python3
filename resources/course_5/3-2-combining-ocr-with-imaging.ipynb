{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining OCR with Imaging\n",
    "\n",
    "In this week of the course we have tip toed into the world of optical character recognition, and while we saw a really\n",
    "nice example of OCR working well with clean text, the more authentic poster image text doesn't seem to come through very\n",
    "well. There are a few things we can do to try and improve our ability to recognize characters and these techniques are\n",
    "rooted in image manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring in our image manipulation libraries\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "# Here is a helper function to display a marked up image with text boxes, adapted from\n",
    "# the example in the previous lecture\n",
    "def ocr_with_boxes(image):\n",
    "    acopy = image.copy()\n",
    "    draw = ImageDraw.Draw(acopy)\n",
    "    for line in pytesseract.image_to_data(image).splitlines()[1:]:\n",
    "        x, y, w, h, c = [float(p) for p in line.split(\"\\t\")[6:11]]\n",
    "        if c > 0:\n",
    "            draw.rectangle((x, y, x + w, y + h), outline=\"red\", width=2)\n",
    "    return acopy\n",
    "\n",
    "\n",
    "# I want to display several different things\n",
    "poster = Image.open(\"food.jpg\")\n",
    "# 1. Metadata about the image\n",
    "print(poster)\n",
    "# 2. The image itself\n",
    "display(poster)\n",
    "# 3. The image marked up with text boxes\n",
    "display(ocr_with_boxes(poster))\n",
    "# 4. The text extracted from the image\n",
    "print(pytesseract.image_to_string(poster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this image recognition isn't really that bad, we see that the bounding boxes tend to be correct, and there are just\n",
    "a few transcription issues with some of the lettering. However, there are a few different techniques you can use in PIL\n",
    "to improve this, so let's go through them and see how it improves the quality of the OCR.\n",
    "\n",
    "### Step 1: Removing Extraneous Information\n",
    "\n",
    "Extraneous information -- pixels that we know are not going to contain text we want -- should be removed. In this image,\n",
    "I think cropping around the food poster itself is probably what we want to do, and you should keep in mind that\n",
    "tesseract was heavily tuned to work well on scans of books, so keeping a margin around your text is a pretty reasonable\n",
    "thing to do.\n",
    "\n",
    "### Step 2: Resize the Image\n",
    "\n",
    "The tesseract docs suggest that larger images will generally work better, so we can experiment a bit with scaling the\n",
    "image to improve the results. I've found tesseract is actually much better with bigger images in practice, and this one\n",
    "is pretty small, being only 515x640 pixels in size.\n",
    "\n",
    "### Step 3: Converting to Black and White\n",
    "\n",
    "Generally, OCR tools do not work well on color images. Realistically, tesseract and other OCR tools convert a color\n",
    "image to a greyscale image before doing text detection. As we saw in last week's lecture though, the way in which you\n",
    "convert a color image to greyscale can change what information is retained. If we convert the image to greyscale before\n",
    "sending it to tesseract, we can ensure we are retaining maximum information.\n",
    "\n",
    "### Step 4: Binarizing the Greyscale Image to Black and White\n",
    "\n",
    "Text generally has high contrast with it's background -- like black text on a white page -- otherwise it makes it very\n",
    "difficult for us humans to read the text. We can exaggerate this even more through a process called binarization, where\n",
    "we change each grey pixel to either black or white based on a threshold. Now, what threshold value we should choose is\n",
    "unclear, and that depends on your source material, but we represent this as a single byte of information -- a number\n",
    "between 1 and 255 that indicates the cutoff between black and white.\n",
    "\n",
    "### Step 5: Using Tesseract Specific Optimizations\n",
    "\n",
    "Tesseract has many different configuration parameters you can pass to it which can improve the quality of the results,\n",
    "including forcing a specific page segmentation algorithm, and setting a limit on the words or characters you want to\n",
    "look for. We can play with these parameters a bit to experiment and see if it leads to an increase in quality.\n",
    "\n",
    "These are just five steps I use to improve my OCR results, and how well they work depends on the kind of image you are\n",
    "dealing with and the level of quality you need to get out of it. Let's play with these in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's tackle the first three together, as we can use PIL for them all\n",
    "image = poster.copy()  # I like to make a copy to preserve the original\n",
    "\n",
    "# First up, let's crop out some of the extraneous information at the top and sides\n",
    "# of the image, I experimentally found these numbers to be solid\n",
    "image = image.crop([85, 80, 425, 540])\n",
    "\n",
    "# Now let's resize the image\n",
    "image = image.resize((image.width * 4, image.height * 4))\n",
    "\n",
    "# Now lets change it to a greyscale (single channel) image\n",
    "image = image.convert(\"L\")\n",
    "\n",
    "# Ok, that's steps 1 through 3. Now we have to binarize (or threshold) the image. This means we will\n",
    "# convert all pixels to either black or white. Remember that the image is now in L mode, so each pixel\n",
    "# is a single byte. We can set a \"threshold\" value as to the cutoff, and I'm going to use 140 as that\n",
    "# number. Feel free to experiment in the notebook and see how changing this threshold affects the image!\n",
    "threshold = 140\n",
    "\n",
    "# Remember that a bytes object in python is immutable, but we can create a new bytearray of the\n",
    "# same size and copy the bytes into it, then do our processing there.\n",
    "new_image = bytearray(image.tobytes())\n",
    "\n",
    "for location, value in enumerate(new_image):\n",
    "    if value < threshold:\n",
    "        new_image[location] = 0\n",
    "    else:\n",
    "        new_image[location] = 255\n",
    "\n",
    "# Create a new image from the bytsarray\n",
    "new_image = PIL.Image.frombytes(image.mode, image.size, bytes(new_image))\n",
    "\n",
    "# Alright, we now have a bigger, cropped, binarized black and white image.\n",
    "display(ocr_with_boxes(new_image))\n",
    "print(pytesseract.image_to_string(new_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so not a huge difference between these results and the initial results right out of the gate. We get rid of a few\n",
    "extraneous characters, but it's still not perfect. We could keep tweaking here, trying different sizes or thresholds,\n",
    "but we can also consider what tesseract can do for us. If you look online at the tesseract documentation you'll find\n",
    "there are a huge number of different parameters we can tweak by setting their values in a configuration file. This is\n",
    "ok, but it doesn't really work well with jupyter notebooks, where we are experimenting real time and writing python\n",
    "directly. The pytesseract library allows us to set some options when we make a call though, so lets give that a try.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are lots of configuration items, I'm just going to show a few. The first one\n",
    "# is to set the language. By default, tesseract will try to recognize all the languages\n",
    "# it knows about. You can set the language to a single language, or a list of languages.\n",
    "config = \"-l eng \"\n",
    "\n",
    "# I don't expect the language to do much, because the default is already english, but\n",
    "# it's good to know this is an option, and tesseract actually has really nice support\n",
    "# for handling multiple languages at once.\n",
    "\n",
    "# Another handy configuration parameter for tesseract is the list of allowable characters\n",
    "# that it should look for. That sounds handy because we're getting some odd symbols\n",
    "# in here, like Â¢, and this should stop that.\n",
    "config = (\n",
    "    config\n",
    "    + '-c tessedit_char_whitelist=\" .0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\\'\"'\n",
    ")\n",
    "print(pytesseract.image_to_string(new_image, config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, well, that's a pretty moderate improvement. Setting the list of allowable characters does help us, but you have to\n",
    "be careful when you do this. You must make sure you are inclusive of all characters -- when I first put this together I\n",
    "didn't include the ampersand and whitespace characters, and it looked pretty funny as a result.\n",
    "\n",
    "I've included below a few more images for you to try and experiment with. I really encourage you to jump into this\n",
    "notebook and see if you can detect the text in these images and, if not, how you might use your abilities with the\n",
    "python imaging library to improve text detection. Open ended exploration and practice is key in becoming better at\n",
    "programming, so give it a shot!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For practice, can you detect the text in the following images?\n",
    "# What differences, if any, do you see between these three images?\n",
    "\n",
    "additional_images = [\"ocr1.jpg\", \"ocr2.jpg\", \"ocr3.jpg\"]\n",
    "for fil in additional_images:\n",
    "    image = Image.open(fil)\n",
    "    image.thumbnail((400, 400))\n",
    "    display(image)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Module 1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
